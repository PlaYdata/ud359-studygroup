{
 "metadata": {
  "name": "",
  "signature": "sha256:04c86ce72cca786df100a794e1713b69607b286eef4cd082e2c65ee09b03561a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u1 = .299\n",
      "u2 = .307\n",
      "N1 = 150\n",
      "N2 = 165\n",
      "s1s = .05\n",
      "s2s = .08 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = (u1 - u2) / (s1s/N1 + s2s/N2)**0.5\n",
      "t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "-0.2796823595120407"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v = (s1s/N1 + s2s/N2)**2 / (s1s**2/(N1**2*(N1-1)) + s2s**2/(N2**2*(N2-1)))\n",
      "v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "307.1987997516727"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"../data/baseball_data.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>handedness</th>\n",
        "      <th>height</th>\n",
        "      <th>weight</th>\n",
        "      <th>avg</th>\n",
        "      <th>HR</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      Tom Brown</td>\n",
        "      <td> R</td>\n",
        "      <td> 73</td>\n",
        "      <td> 170</td>\n",
        "      <td> 0.000</td>\n",
        "      <td>   0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Denny Lemaster</td>\n",
        "      <td> R</td>\n",
        "      <td> 73</td>\n",
        "      <td> 182</td>\n",
        "      <td> 0.130</td>\n",
        "      <td>   4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      Joe Nolan</td>\n",
        "      <td> L</td>\n",
        "      <td> 71</td>\n",
        "      <td> 175</td>\n",
        "      <td> 0.263</td>\n",
        "      <td>  27</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>    Denny Doyle</td>\n",
        "      <td> L</td>\n",
        "      <td> 69</td>\n",
        "      <td> 175</td>\n",
        "      <td> 0.250</td>\n",
        "      <td>  16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  Jose Cardenal</td>\n",
        "      <td> R</td>\n",
        "      <td> 70</td>\n",
        "      <td> 150</td>\n",
        "      <td> 0.275</td>\n",
        "      <td> 138</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "             name handedness  height  weight    avg   HR\n",
        "0       Tom Brown          R      73     170  0.000    0\n",
        "1  Denny Lemaster          R      73     182  0.130    4\n",
        "2       Joe Nolan          L      71     175  0.263   27\n",
        "3     Denny Doyle          L      69     175  0.250   16\n",
        "4   Jose Cardenal          R      70     150  0.275  138"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_L = df[df[\"handedness\"] == \"L\"]\n",
      "df_R = df[df[\"handedness\"] == \"R\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = scipy.stats.ttest_ind(df_L[\"avg\"],df_R[\"avg\"],equal_var=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "(array(3.9867064465971422), 7.4823915909703493e-05)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if results[1] < 0.05:\n",
      "    print (False, results)\n",
      "else:\n",
      "    print (True, results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(False, (array(3.9867064465971422), 7.4823915909703493e-05))\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import scipy.stats\n",
      "import pandas as pd\n",
      "\n",
      "def compare_averages(filename):\n",
      "    \"\"\"\n",
      "    Performs a t-test on two sets of baseball data (left-handed and right-handed hitters).\n",
      "\n",
      "    You will be given a csv file that has three columns.  A player's\n",
      "    name, handedness (L for lefthanded or R for righthanded) and their\n",
      "    career batting average (called 'avg'). You can look at the csv\n",
      "    file via the following link:\n",
      "    https://www.dropbox.com/s/xcn0u2uxm8c4n6l/baseball_data.csv\n",
      "    \n",
      "    Write a function that will read that the csv file into a pandas data frame,\n",
      "    and run Welch's t-test on the two cohorts defined by handedness.\n",
      "    \n",
      "    One cohort should be a data frame of right-handed batters. And the other\n",
      "    cohort should be a data frame of left-handed batters.\n",
      "    \n",
      "    We have included the scipy.stats library to help you write\n",
      "    or implement Welch's t-test:\n",
      "    http://docs.scipy.org/doc/scipy/reference/stats.html\n",
      "    \n",
      "    With a significance level of 95%, if there is no difference\n",
      "    between the two cohorts, return a tuple consisting of\n",
      "    True, and then the tuple returned by scipy.stats.ttest.  \n",
      "    \n",
      "    If there is a difference, return a tuple consisting of\n",
      "    False, and then the tuple returned by scipy.stats.ttest.\n",
      "    \n",
      "    For example, the tuple that you return may look like:\n",
      "    (True, (9.93570222, 0.000023))\n",
      "    \"\"\"\n",
      "    \n",
      "    df = pd.read_csv(filename)\n",
      "    df_L = df[df[\"handedness\"] == \"L\"]\n",
      "    df_R = df[df[\"handedness\"] == \"R\"]\n",
      "    results = scipy.stats.ttest_ind(df_L[\"avg\"],df_R[\"avg\"],equal_var=False)\n",
      "    if results[1] < 0.05:\n",
      "        return (False, results)\n",
      "    else:\n",
      "        return (True, results)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.multiply?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1 = np.arange(9.0).reshape((3, 3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([[ 0.,  1.,  2.],\n",
        "       [ 3.,  4.,  5.],\n",
        "       [ 6.,  7.,  8.]])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x2 = np.arange(3.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([ 0.,  1.,  2.])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.multiply(x1, x2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "array([[  0.,   1.,   4.],\n",
        "       [  0.,   4.,  10.],\n",
        "       [  0.,   7.,  16.]])"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import pandas\n",
      "\n",
      "def compute_cost(features, values, theta):\n",
      "    \"\"\"\n",
      "    Compute the cost of a list of parameters, theta, given a list of features (input \n",
      "data points) and values (output data points).\n",
      "    \"\"\"\n",
      "    m = len(values)\n",
      "    sum_of_square_errors = numpy.square(numpy.dot(features, theta) - values).sum()\n",
      "    cost = sum_of_square_errors / (2*m)\n",
      "\n",
      "    return cost\n",
      "\n",
      "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
      "    \"\"\"\n",
      "    Perform gradient descent given a data set with an arbitrary number of features.\n",
      "    \"\"\"\n",
      "\n",
      "    # Write code here that performs num_iterations updates to the elements of theta.\n",
      "    # times. Every time you compute the cost for a given list of thetas, append it \n",
      "    # to cost_history.\n",
      "    \n",
      "    cost_history = []\n",
      "\n",
      "    ###########################\n",
      "    ### YOUR CODE GOES HERE ###\n",
      "    ###########################\n",
      "    \n",
      "    m = len(values)\n",
      "    \n",
      "    for i in range(num_iterations):\n",
      "        pred = numpy.dot(features, theta)\n",
      "        theta = theta - alpha/m*numpy.dot(pred-values,features)\n",
      "        cost = compute_cost(features, values, theta)\n",
      "    \n",
      "        cost_history.append(cost)\n",
      "\n",
      "    return theta, pandas.Series(cost_history) # leave this line for the grader\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def compute_r_squared(data, predictions):\n",
      "    # Write a function that, given two input numpy arrays, 'data', and 'predictions,'\n",
      "    # returns the coefficient of determination, R^2, for the model that produced \n",
      "    # predictions.\n",
      "    # \n",
      "    # Numpy has a couple of functions -- np.mean() and np.sum() --\n",
      "    # that you might find useful, but you don't have to use them.\n",
      "\n",
      "    # YOUR CODE GOES HERE\n",
      "   \n",
      "    data_mean = np.mean(data)\n",
      "    r_squared = 1 - np.sum((data - predictions)**2)/np.sum((data - data_mean)**2)\n",
      "    \n",
      "    \n",
      "    return r_squared"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def entries_histogram(turnstile_weather):\n",
      "    '''\n",
      "    Before we perform any analysis, it might be useful to take a\n",
      "    look at the data we're hoping to analyze. More specifically, let's \n",
      "    examine the hourly entries in our NYC subway data and determine what\n",
      "    distribution the data follows. This data is stored in a dataframe\n",
      "    called turnstile_weather under the ['ENTRIESn_hourly'] column.\n",
      "    \n",
      "    Let's plot two histograms on the same axes to show hourly\n",
      "    entries when raining vs. when not raining. Here's an example on how\n",
      "    to plot histograms with pandas and matplotlib:\n",
      "    turnstile_weather['column_to_graph'].hist()\n",
      "    \n",
      "    Your histograph may look similar to bar graph in the instructor notes below.\n",
      "    \n",
      "    You can read a bit about using matplotlib and pandas to plot histograms here:\n",
      "    http://pandas.pydata.org/pandas-docs/stable/visualization.html#histograms\n",
      "    \n",
      "    You can see the information contained within the turnstile weather data here:\n",
      "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv\n",
      "    '''\n",
      "    \n",
      "    plt.figure()\n",
      "    turnstile_weather[turnstile_weather[\"rain\"] == 1]['ENTRIESn_hourly'].hist() # your code here to plot a historgram for hourly entries when it is raining\n",
      "    turnstile_weather[turnstile_weather[\"rain\"] == 0]['ENTRIESn_hourly'].hist() # your code here to plot a historgram for hourly entries when it is not raining\n",
      "    return plt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "import scipy.stats\n",
      "import pandas\n",
      "\n",
      "def mann_whitney_plus_means(turnstile_weather):\n",
      "    '''\n",
      "    This function will consume the turnstile_weather dataframe containing\n",
      "    our final turnstile weather data. \n",
      "    \n",
      "    You will want to take the means and run the Mann Whitney U-test on the \n",
      "    ENTRIESn_hourly column in the turnstile_weather dataframe.\n",
      "    \n",
      "    This function should return:\n",
      "        1) the mean of entries with rain\n",
      "        2) the mean of entries without rain\n",
      "        3) the Mann-Whitney U-statistic and p-value comparing the number of entries\n",
      "           with rain and the number of entries without rain\n",
      "    \n",
      "    You should feel free to use scipy's Mann-Whitney implementation, and you \n",
      "    might also find it useful to use numpy's mean function.\n",
      "    \n",
      "    Here are the functions' documentation:\n",
      "    http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\n",
      "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
      "    \n",
      "    You can look at the final turnstile weather data at the link below:\n",
      "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv\n",
      "    '''\n",
      "    \n",
      "    ### YOUR CODE HERE ###\n",
      "    rain_array = turnstile_weather[turnstile_weather[\"rain\"] == 1][\"ENTRIESn_hourly\"]\n",
      "    no_rain_array = turnstile_weather[turnstile_weather[\"rain\"] == 0][\"ENTRIESn_hourly\"]\n",
      "    \n",
      "    with_rain_mean = rain_array.mean()\n",
      "    without_rain_mean = no_rain_array.mean()\n",
      "    \n",
      "    #print \"with_rain_mean, without_rain_mean = \",with_rain_mean, without_rain_mean\n",
      "    \n",
      "    U, p = scipy.stats.mannwhitneyu(rain_array, no_rain_array)\n",
      "    #print \"U, p = \",U, p\n",
      "    \n",
      "    return with_rain_mean, without_rain_mean, U, p # leave this line for the grader\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import numpy\n",
      "import pandas\n",
      "\n",
      "def normalize_features(array):\n",
      "   \"\"\"\n",
      "   Normalize the features in the data set.\n",
      "   \"\"\"\n",
      "   array_normalized = (array-array.mean())/array.std()\n",
      "   mu = array.mean()\n",
      "   sigma = array.std()\n",
      "\n",
      "   return array_normalized, mu, sigma\n",
      "\n",
      "def compute_cost(features, values, theta):\n",
      "    \"\"\"\n",
      "    Compute the cost of a list of parameters, theta, given a list of features (input \n",
      "data points) and values (output data points).\n",
      "    \"\"\"\n",
      "    m = len(values)\n",
      "    sum_of_square_errors = numpy.square(numpy.dot(features, theta) - values).sum()\n",
      "    cost = sum_of_square_errors / (2*m)\n",
      "\n",
      "    return cost\n",
      "\n",
      "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
      "    \"\"\"\n",
      "    Perform gradient descent given a data set with an arbitrary number of features.\n",
      "    \"\"\"\n",
      "\n",
      "    # Write code here that performs num_iterations updates to the elements of theta.\n",
      "    # times. Every time you compute the cost for a given list of thetas, append it \n",
      "    # to cost_history.\n",
      "    \n",
      "    cost_history = []\n",
      "\n",
      "    ###########################\n",
      "    ### YOUR CODE GOES HERE ###\n",
      "    ###########################\n",
      "    \n",
      "    m = len(values)\n",
      "    \n",
      "    for i in range(num_iterations):\n",
      "        pred = numpy.dot(features, theta)\n",
      "        theta = theta - alpha/m*numpy.dot(pred-values,features)\n",
      "        cost = compute_cost(features, values, theta)\n",
      "    \n",
      "        cost_history.append(cost)\n",
      "\n",
      "    return theta, pandas.Series(cost_history) # leave this line for the grader\n",
      "\n",
      "def predictions(dataframe):\n",
      "    '''\n",
      "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
      "    Using the information stored in the dataframe, let's predict the ridership of\n",
      "    the NYC subway using linear regression with gradient descent.\n",
      "    \n",
      "    You can see the information contained in the turnstile weather dataframe here:\n",
      "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
      "    \n",
      "    Your prediction should have a R^2 value of 0.40 or better.\n",
      "    \n",
      "    Note: Due to the memory and CPU limitation of our Amazon EC2 instance, we will\n",
      "    give you a random subet (~15%) of the data contained in \n",
      "    turnstile_data_master_with_weather.csv\n",
      "    \n",
      "    If you receive a \"server has encountered an error\" message, that means you are \n",
      "    hitting the 30-second limit that's placed on running your program. Try using a \n",
      "    smaller number for num_iterations if that's the case.\n",
      "    \n",
      "    If you are using your own algorithm/models, see if you can optimize your code so \n",
      "    that it runs faster.\n",
      "    '''\n",
      "\n",
      "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
      "    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi']].join(dummy_units)\n",
      "    values = dataframe[['ENTRIESn_hourly']]\n",
      "    m = len(values)\n",
      "\n",
      "    features, mu, sigma = normalize_features(features)\n",
      "\n",
      "    features['ones'] = np.ones(m)\n",
      "    features_array = np.array(features)\n",
      "    values_array = np.array(values).flatten()\n",
      "\n",
      "    #Set values for alpha, number of iterations.\n",
      "    alpha = 0.1 # please feel free to change this value\n",
      "    num_iterations = 75 # please feel free to change this value\n",
      "\n",
      "    #Initialize theta, perform gradient descent\n",
      "    theta_gradient_descent = np.zeros(len(features.columns))\n",
      "    theta_gradient_descent, cost_history = gradient_descent(features_array, \n",
      "                                                            values_array, \n",
      "                                                            theta_gradient_descent, \n",
      "                                                            alpha, \n",
      "                                                            num_iterations)\n",
      "    \n",
      "    predictions = np.dot(features_array, theta_gradient_descent)\n",
      "    return predictions\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def plot_residuals(turnstile_weather, predictions):\n",
      "    '''\n",
      "    Using the same methods that we used to plot a histogram of entries\n",
      "    per hour for our data, why don't you make a histogram of the residuals\n",
      "    (that is, the difference between the original hourly entry data and the predicted values).\n",
      "\n",
      "    Based on this residual histogram, do you have any insight into how our model\n",
      "    performed?  Reading a bit on this webpage might be useful:\n",
      "\n",
      "    http://www.itl.nist.gov/div898/handbook/pri/section2/pri24.htm\n",
      "    '''\n",
      "    \n",
      "    #print turnstile_weather\n",
      "    \n",
      "    plt.figure()\n",
      "    (turnstile_weather['ENTRIESn_hourly'] - predictions).hist()\n",
      "    return plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "import sys\n",
      "\n",
      "def compute_r_squared(data, predictions):\n",
      "    '''\n",
      "    In exercise 5, we calculated the R^2 value for you. But why don't you try and\n",
      "    and calculate the R^2 value yourself.\n",
      "    \n",
      "    Given a list of original data points, and also a list of predicted data points,\n",
      "    write a function that will compute and return the coefficient of determination (R^2)\n",
      "    for this data.  numpy.mean() and numpy.sum() might both be useful here, but\n",
      "    not necessary.\n",
      "\n",
      "    Documentation about numpy.mean() and numpy.sum() below:\n",
      "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
      "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\n",
      "    '''\n",
      "    \n",
      "    # your code here\n",
      "    \n",
      "    data_mean = np.mean(data)\n",
      "    r_squared = 1 - np.sum((data-predictions)**2) / np.sum((data-data_mean)**2)\n",
      "    \n",
      "    return r_squared"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}